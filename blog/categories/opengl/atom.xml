<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:opengl | 番茄手册]]></title>
  <link href="http://www.newtomato.me/blog/categories/opengl/atom.xml" rel="self"/>
  <link href="http://www.newtomato.me/"/>
  <updated>2018-02-11T00:32:04+08:00</updated>
  <id>http://www.newtomato.me/</id>
  <author>
    <name><![CDATA[newtomato]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenGL基础之普通光照]]></title>
    <link href="http://www.newtomato.me/blog/2018/01/07/openglji-chu-zhi-pu-tong-guang-zhao"/>
    <updated>2018-01-07T18:33:45+08:00</updated>
    <id>http://www.newtomato.me/blog/2018/01/07/openglji-chu-zhi-pu-tong-guang-zhao</id>
    <content type="html"><![CDATA[<p>opengl中有三种光照，环境光，漫反射以及镜面光源。<br />
不同物体可以通过的材质（Material）对光照的参数的设置能够达到模拟真实的效果。</p>

<p>三种光照的基本知识，推导公式，以及Material是干什么用的均在<strong>learnopengl</strong>的教程中已经有详细的介绍，我将在这篇博文里面将按照自己的理解整理一下，也好加深自己的理解。</p>

<p>光照对物体的影响是通过他对物体颜色变量的加成而达到效果的。也就是说光照并没有带来新的元素，只是影响了颜色。</p>

<pre><code>object_color = new_light_color * object_color
</code></pre>

<!--more-->
<p>对环境光而言，因为大家都收到这个光照的影响。所以环境光ambient是一个常量。</p>

<pre><code>new_light_color = ambient * light_color * 特殊材质变量
</code></pre>

<p>对漫反射而言，需要参考下面的图计算发射之后颜色。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-01-07-15153188795257.jpg" alt="" /><br />
光源的位置<code>light_pos</code>以及当前照射那点的法线向量<code>N</code>（此法线在顶点数据中已经设定好了，一般是出模型Mesh的时候已经包含了进来），他们之间的角度决定这一点的亮度，角度越小，光照越垂直于此点。所以求两个向量之间的夹角。使用向量的点乘。</p>

<pre><code>vec3 light_dir = light_pos - frag_pos
float diff = max(dot(norm, light_dir), 0.0);
vec3 new_light_color = diff * light_color * 特殊材质漫反射变量
</code></pre>

<p>对于镜面反射而言，和漫反射不同的时候，不仅仅有光源和法线还需要有观察者的位置。因为镜面反射对观察者有影响。观察者位置不同看到的镜面反射也不同。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-01-07-15153193377520.jpg" alt="" /></p>

<p>镜面反射求的是反射光线对观察者的影响，因此就是观察者向量在反射光线向量上的投影。也就是这两个向量之间的夹角。</p>

<pre><code>vec3 eye_dir = normalize(eye_pos - FragPos);
//此处注意，为了便于理解，我这里的light_dir向量方向是从光源到点的方向。因为reflect函数，第一个参数要求就是光源到点的方向。教程中使用的-lightDir，是因为lightDir是从点到光源。
vec3 reflectDir = reflect(light_dir, norm);
float spec = pow(max(dot(reflectDir,eye_dir),0),特殊材质反光度变量)
vec3 new_light_color = spec * light_color * 特殊材质镜面光变量

</code></pre>

<p>上面三种光照，会产生新的<code>new_light_color</code>，此时全部都作用到object身上就是</p>

<pre><code>vec3 result = (ambient(环境光) + diffuse（漫反射光） + specular（镜面光）) * objectColor;
FragColor = vec4(result, 1.0);
</code></pre>

<p>上面每个光照的公式中均有一个特殊材质变量，这些变量就是材质Material的控制变量。</p>

<pre><code>struct Material {
    vec3 ambient;
    vec3 diffuse;
    vec3 specular;
    float shininess;
}; 

uniform Material material;
</code></pre>

<p>通过对三种光照公式的分析，抽取除了材质这样的数据结构。所以在游戏引擎中，我们只要对object选择不同材质，光照就会发生变化，原因仅在于此。<br />
另外上面还有一个很重要的点需要提出来说一下，就是在计算向量加减的时候，使用的是世界坐标系。<br />
尤其是在计算法线向量的转换的时候，我们需要将法线向量从模型坐标系转为世界坐标系。使用专门的法线矩阵。也就是模型矩阵左上角3x3矩阵的逆矩阵的转置矩阵。非常拗口的概念。<br />
对应opengl函数就是<code>normal = mat3(transpose(inverse(model))) * aNormal</code>;<br />
不对法线向量进行坐标转换，则会导致上面向量不在同一个坐标系，因而加减会出现问题。<br />
如果不是世界坐标系，是观察者坐标系，则需要将里面的<code>model</code>变为<code>view*mode</code>。</p>

<p>这里分享的是光照的基础知识，还有光照引申出来的不同灯光效果，光照贴图将放到下一章节总结。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenGL基础之常用调用接口]]></title>
    <link href="http://www.newtomato.me/blog/2018/01/07/openglji-chu-zhi-chang-yong-diao-yong-jie-kou"/>
    <updated>2018-01-07T17:13:16+08:00</updated>
    <id>http://www.newtomato.me/blog/2018/01/07/openglji-chu-zhi-chang-yong-diao-yong-jie-kou</id>
    <content type="html"><![CDATA[<p>学习opengl的时候，我们经常用到的函数大致有如下几个，这些函数之间奇怪的命名方式一开始总让我们摸不着头脑。例如<code>glGenVertexArrays</code>之后，怎么传递了数据，怎么使用了这些数据？</p>

<pre><code>glGenVertexArrays(1, &amp;VAO)
glGenBuffers(1, &amp;VBO);
glBindVertexArray(VAO);
glBindBuffer(GL_ARRAY_BUFFER, VBO);
glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(GLfloat), (GLvoid*)0);
glDrawArrays(GL_TRIANGLES, 0, 36);
</code></pre>

<p>今天我们就梳理一下这些函数的含义。从我理解的角度讲解一下，增加大家对他的印象。<br />
<!--more--></p>

<p>首先opengl的函数都从<code>glGen*(GLsizei n​, GLuint *objects​)</code>的函数开始，这个函数创建了一个opengl对象，第二个参数就是这个对象的引用。<br />
对象创建结束之后，还需要给他数据，并且告诉他这个数据的结构。例如我们上面创建的<code>VBO</code>。<br />
<code>VBO(vertical buffer object)</code>是顶点数据，创建<code>glGenBuffers</code>和激活<code>glBindBuffer</code>之后，我们就可以传递数据<code>(glBufferData)</code>，同时对这个数据进行结构说明<code>(glVertexAttribPointer)指针从哪里开始，步长多少，获取多少数据等</code>。<br />
这样我们的顶点缓冲数据都会存在VBO这个引用中。<br />
顶点缓冲数据如此，纹理也是如此，创建<code>glGenTextures</code>，激活<code>glBindTexture</code>以及数据传递<code>glTexImage2D</code>。</p>

<p>经过这些函数数据设置OK，然后调用<code>glDrawArrays</code>，就可以将图像的骨和皮画出来。</p>

<p>接下来说细节，纹理相对简单一些放在后面，顶点数据既然有了<code>VBO</code>，为什么要使用<code>VAO（Vertex Array Object）</code>呢？因为一般情况下，一个显示物体不仅仅有一个或者一种VBO，还有有<code>EBO（他另一个名字是IBO）</code>。因此开发者考虑能不能将一个物体用到的所有缓冲对象都包裹在一切，用到的时候，直接这一个用。因此他们就开发出了<code>VAO</code>。</p>

<p>VAO创建了之后，不需要给他任何数据，只要在激活他之后，对VBO操作就可以了，opengl内部会自动将这个VBO绑定到VAO上面。只需要操作这个VAO就可以了。这段话的意思并不是说VAO可以脱离VBO，而是说创建多个VBO之后，如果挂靠在一个VAO上会更容易管理。如果没有<code>VBO</code>，VAO则没有任何用处。</p>

<p>例如在漫反射贴图的opengl教程中，有下面一段代码：</p>

<pre><code>// 顶点输入
GLfloat vertices[] = {
		// 顶点             // 法线              // 纹理坐标
		-0.5f, -0.5f, -0.5f,  0.0f,  0.0f, -1.0f,  0.0f,  0.0f,
		.....
}；

//--------------设置containerVAO开始--------------------------
GLuint VBO, containerVAO;
glGenVertexArrays(1, &amp;containerVAO);
glGenBuffers(1, &amp;VBO);

// 把顶点数组复制到缓冲中供OpenGL使用
glBindBuffer(GL_ARRAY_BUFFER, VBO);
glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
// !!! Bind the Vertex Array Object first, then bind and set vertex buffer(s) and attribute pointer(s).
glBindVertexArray(containerVAO);
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)0);
glEnableVertexAttribArray(0);
glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(3 * sizeof(GLfloat)));
glEnableVertexAttribArray(1);
glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)(6 * sizeof(GLfloat)));
glEnableVertexAttribArray(2);
glBindVertexArray(0);
//--------------设置containerVAO结束--------------------------


//--------------设置lightVAO开始------------------------------
// 设置光照的顶点数组对象(VAO)，顶点缓冲对象(VBO)共用
GLuint lightVAO;
glGenVertexArrays(1, &amp;lightVAO);
glBindVertexArray(lightVAO);
// 只需要绑定VBO不用再次设置VBO的数据，因为容器(物体)的VBO数据中已经包含了正确的立方体顶点数据
glBindBuffer(GL_ARRAY_BUFFER, VBO);
// 设置灯立方体的顶点属性指针(仅设置灯的顶点数据)
glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 8 * sizeof(GLfloat), (GLvoid*)0); // Note that we skip over the other data in our buffer object (we don't need the normals/textures, only positions).
glEnableVertexAttribArray(0);
glBindVertexArray(0);
//--------------设置lightVAO结束------------------------------
// 读取贴图

</code></pre>
<p>我们并没有给VAO数据，<code>glBufferData</code>之后数据还是在VBO中，所以VAO只是包裹了这个VBO。<br />
上面对opengl所需要的数据先做处理，这些是静态数据不会发生变化，会变化的的数据则放在了下面while循环里面。下面我们对while循环函数进行分析。</p>

<pre><code>...
// 渲染指令
glClearColor(0.1f, 0.1f, 0.1f, 1.0f);
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

....
箱子使用的shader进行参数get和set。
....

// 激活纹理
glActiveTexture(GL_TEXTURE0);
glBindTexture(GL_TEXTURE_2D, diffuseMap);

//使用上面创建的containerVAO对象
glBindVertexArray(containerVAO);
glDrawArrays(GL_TRIANGLES, 0, 36);
glBindVertexArray(0); //清理VAO对象，但不是释放。

...
灯的shader进行参数get和set。
...
//激活灯的lightVAO对象。上面已经创建，这里直接使用即可。如果在while循环里面不断创建会浪费内存。
glBindVertexArray(lightVAO);
glDrawArrays(GL_TRIANGLES, 0, 36);
glBindVertexArray(0);

// 交换缓冲,一般采用前后双缓冲，这样屏幕变化玩家几乎看不到中间的切换。
glfwSwapBuffers(window);

</code></pre>

<p>上面分析下来，可以看出VAO至少是包裹了VBO，且VBO还可以被重用。箱子和灯都是立方体，所以一份VBO对象给箱子使用也给灯使用。<br />
这样VBO重用减少了内存的开销，VAO则方便了顶点数据的管理。</p>

<p>说完顶点数据相关的VAO，VBO，在来看看纹理。</p>

<p>但上面代码，texture的数据映射关系是在<strong>vertices</strong>中，但是具体的纹理并不受VAO的管理。纹理数据被传递给diffuseMap引用。而diffuseMap虽然在VAO后面，但是没有挂靠于VAO，这些实现全都是OpenGL内部实现的。也就是说VAO只能管理VBO和EBO，其他的依然是自己管理自己。</p>

<pre><code>// 读取贴图
GLuint diffuseMap;
glGenTextures(1, &amp;diffuseMap);
//int width, height;
unsigned char* image;
// 漫反射贴图
image = stbi_load("container2.jpg", &amp;width, &amp;height, 0, 0);
glBindTexture(GL_TEXTURE_2D, diffuseMap);
glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, image);
glGenerateMipmap(GL_TEXTURE_2D);
stbi_image_free(image);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST_MIPMAP_NEAREST);
glBindTexture(GL_TEXTURE_2D, 0);
</code></pre>
<p>上面代码创建了diffuseMap引用，读取硬盘上jpg图片，将数据通过glTexImage2D传递给GL_TEXTURE_2D目标，其实GL_TEXTURE_2D目标已经和diffuseMap引用绑定在了一起。所以你可以理解diffuseMap里面有一个GL_TEXTURE_2D目标，我们对GL_TEXTURE_2D进行<code>glTexParameteri</code>设置就是对diffuseMap的设置。<br />
最后，<code>glBindTexture(GL_TEXTURE_2D, 0);</code>并不是释放diffuseMap引用。而是opengl纹理绑定的状态进行了清理。以便于在while循环中重新设置。<br />
这一局不调用也不会出问题，因为下面被重新设置了。不过这样做比较清晰不容易出问题。</p>

<p>while循环中在上面的代码已经有，可在读一遍。</p>

<p>总的来说，opengl看似复杂，实则简单清楚，只要我们对常用的几个函数了熟于心。以此为突破口，就不会被他复杂的表面欺骗。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenGL基础之透视投影矩阵]]></title>
    <link href="http://www.newtomato.me/blog/2017/12/16/opengl-tou-shi-tou-ying-ju-zhen"/>
    <updated>2017-12-16T18:12:54+08:00</updated>
    <id>http://www.newtomato.me/blog/2017/12/16/opengl-tou-shi-tou-ying-ju-zhen</id>
    <content type="html"><![CDATA[<p>今天我们来讲解一下怎么推导投影矩阵。投影矩阵的作用是剔除不在锥视体内的坐标，同时将锥视体内的坐标转换为标准化设备坐标。</p>

<p>投影矩阵分为两种，一种是2D常用的正交投影，另外一种就是3D游戏常用的透视投影，透视投影更符合我们对现实世界的模拟。</p>

<p>正如上篇博文说道坐标转换的过程。如下图所示：</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15128199931966.jpg" alt="-" /></p>

<p>而<strong>透视矩阵</strong>是透视除法的核心。<br />
按照 <code>P(NDC) = M(透视矩阵) * P(C)</code>的公式如（图1），就能将裁剪坐标转为规范化坐标。</p>

<!--more-->

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15126253778019_1.jpg" alt="-w150" /><br />
(图1)</p>

<p>带e下标的表示摄像机坐标，即通过<code>模型矩阵*摄像机矩阵*物体本地坐标</code>计算得来的坐标<br />
带c下标的标示剪裁坐标，P是投影矩阵。<br />
带n下标的是设备标准化坐标，标准化坐标的范围在[-1,1]内，所以需要将裁剪坐标归一化处理。<br />
最终根据<code>glViewPort()</code>传递过来的屏幕大小和上面的标准化坐标，便能转换成屏幕标准。</p>

<h3 id="section">透视锥视体</h3>
<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15126256321092.jpg" alt="-w300" /><br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15126418783276.jpg" alt="-w300" /><br />
锥视体有<strong>near，far，宽高比以及fov(field of view，可以看成是视角)</strong>来决定箱体的大小。<br />
只要控制任何一个变量，都能让锥视体变化。<br />
上图中，坐标原点假设在（0，0，0）,那么近平面的中心点在(0,0,near),远平面的中心同理在（0，0，far）</p>

<h2 id="section-1">透视矩阵推导</h2>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15126252106319.jpg" alt="-w350" /><br />
在上图，对near进行划分，l=&gt;left,t=&gt;top,r=&gt;right,b=&gt;bottom。<br />
则如果我们从上面往下看这个锥视体。只有<strong>xz</strong>这个平面。</p>

<p>有三角形相似性，我们得知：<code>Ze/Zp = Xe/Xp</code>。<br />
我们使用的是near平面。所以Zp的大小是near。方向是z负轴，所有<code>Zp=-n</code>，带入到上面公式，<code>Xp = -n* Xe/Ze</code>。如下图所示：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134146322302.png" alt="-w200" /><br />
同理，我们可以求得<code>Yp</code>（从X轴看向去，只有YZ平面）。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134147063339.png" alt="" /><br />
因此将一个点投影到锥视体的近平面的坐标（Xp,Yp,Zp）便计算出来。接下来计算这个P点坐标和规范化设备坐标的转换。P坐标的x,y最终要转换成[-1,1]区间。如下图所示，横轴是以Xp为轴，纵轴是Xn。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134159083184.jpg" alt="-w200" /><br />
因此他们满足的关系是二元一次方程:<code>Xn = k*Xp + b</code></p>

<pre><code>1  = k*r + b
-1 = k*l + b

k = 2/(r -l)
b = -k(r+l)/2

Xn = 2/(r-l)*Xp - (r+l)/(r-l)
</code></pre>

<p>同理Yn和Yp之间的关系也是如此。</p>

<pre><code>Yn = 2/(t-b) * Yp - (t+b)/(t-b)
</code></pre>

<p>将上面Xp,Yp的公式带入到Xn,Yn中。如果下图所示：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134168329201_2.jpg" alt="-w200" /><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134168191851_2.jpg" alt="-w200" /><br />
在最上面的公式，我们知道<code>Xn=Xc/Wc</code>,所以设<code>Wc=Ze</code>。推导出矩阵如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134170212170.jpg" alt="" /><br />
矩阵中第三行还没有解决。<br />
Z轴的数值转化之后的目的是用来进行clipping和Depth Test。<br />
我们对上面的矩阵进行修改，用来计算Zn和Ze之间的关系。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134174579880.jpg" alt="" /><br />
在摄像机矩阵中We等于1，因此上面公式可以简化。<br />
同时Zp=-near的时候，Zn=-1，Zp=-far的时候，Zn=1。<br />
通过上述条件。我们计算得知：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134176793143.jpg" alt="-w200" /></p>

<p>所以投影矩阵最终的样子如下：</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134182206777_2.png" alt="" /><br />
由于锥视体都是对称的。因此r和l的值相等。t和b的值相等。上面的公式又可以转化为：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-16-15134184015016_2.jpg" alt="" /></p>

<p>到此投影矩阵的推导基本完成。</p>

<p>工作中常用到投影，却很少为此深入了解。知其然最好能知其所以然。为此研读各类资料，在此整理出来，既是对自己的一个总结，也希望借此捋一捋这方面的知识。了解之后，对opengl以及图像学会有不同看问题的角度。如上面有误，还请不吝指出。</p>

<h2 id="section-2">参考文档</h2>

<ol>
  <li><a href="https://www.cnblogs.com/graphics/archive/2012/07/25/2582119.html">透视投影详解</a></li>
  <li><a href="http://www.songho.ca/opengl/gl_projectionmatrix.html">OpenGL Projection Matrix</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenGL基础之模板缓存]]></title>
    <link href="http://www.newtomato.me/blog/2017/12/15/openglji-chu-zhi-mo-ban-huan-cun"/>
    <updated>2017-12-15T23:50:52+08:00</updated>
    <id>http://www.newtomato.me/blog/2017/12/15/openglji-chu-zhi-mo-ban-huan-cun</id>
    <content type="html"><![CDATA[<p>一个支持OpenGL绘制的窗口（即一个默认的帧缓存）可以由以下一些组合构成：多达四个颜色缓存,深度缓存,模板缓存,多重采样（MSAA）缓存,辅助缓存。</p>

<p>我们今天主要讨论模板缓存。模版缓冲（STENCIL_BUFFER）通过设置模版缓冲每个像素的值,我们可以指定在渲染的时候只渲染某些像素,从而可以达到一些特殊的效果。</p>

<p>通过对cocos2dx里面遮罩裁剪功能的分析，对模板缓存有个初步认识。<br />
<!--more--></p>

<h2 id="cocos2dx-">cocos2dx 遮罩的实现</h2>

<pre><code>local TestClippingScene  = class("TestClippingScene",cc.load("mvc").ViewBase)

function TestClippingScene:onCreate(event)
	local mask = display.newSprite("MainSceneBg.jpg")
	local sencialnode = display.newSprite("BugSpider.png")

	local clippingNode = cc.ClippingNode:create(sencialnode)
	
            -- clippingNode:setInverted(true) --注释1
            -- clippingNode:setAlphaThreshold(0)--注释2
            clippingNode:addChild(mask)

            self:addChild(clippingNode)
            clippingNode:setPosition(display.center)
            
end

return TestClippingScene
</code></pre>
<p>运行上面的代码得到的如下图像。由于没有Alpha测试，导致以图片的矩形为准做遮罩。</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-IMG_1426.png" alt="IMG_1426" /><br />
将<strong>注释2</strong>的取消掉。就会如下所示。透明区域不起作用。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-IMG_1427.png" alt="IMG_1427" /></p>

<p>将<strong>注释1</strong>的取消掉，则得到如下的效果:<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-IMG_1428.png" alt="IMG_1428" /></p>

<p>具体的原理是什么呢？我们需要深入到cocos2dx的源码中。</p>

<h2 id="cocos2dx">cocos2dx中遮罩裁剪的原理</h2>

<h3 id="section">源码阅读</h3>

<p>我们通过阅读ClippingNode.cpp的代码知道，真正实现裁剪的代码是：<code>StencilStateManager::onBeforeVisit()</code></p>

<pre><code>void StencilStateManager::onBeforeVisit()
{
	...

	glDepthMask(GL_FALSE);
	RenderState::StateBlock::_defaultState-&gt;setDepthWrite(false);
	
	glStencilFunc(GL_NEVER, mask_layer, mask_layer);
	//这里的意思是无论什么像素都不会通过模板测试，也就是全部像素都会失败。
	glStencilOp(!_inverted ? GL_ZERO : GL_REPLACE, GL_KEEP, GL_KEEP);
	//如果不是_inverted模式，模板填充0，如果是则填充mask_layer。
	//因为上面失败，所以这里如果是普通遮罩，_inverted为false，则模板缓存里面会全部设置成0。
	//那么也就意味着什么都画不上去。
	drawFullScreenQuadClearStencil();    
	//画一个全屏的矩形，整理模板缓存。上面代码执行之后，模板缓存的样子如(图1)
	
	glStencilFunc(GL_NEVER, mask_layer, mask_layer);
	glStencilOp(!_inverted ? GL_REPLACE : GL_ZERO, GL_KEEP, GL_KEEP);
	//如果是普通遮罩，那么像素上面因为失败，这里会全部替换成mask_layer（glStencilFunc的第二个参数）的值。可参考（图2）
	
	//下面是Alpha Test。
	if (_alphaThreshold &lt; 1) {
	#if !CC_CLIPPING_NODE_OPENGLES
	    _currentAlphaTestEnabled = glIsEnabled(GL_ALPHA_TEST);
	    glGetIntegerv(GL_ALPHA_TEST_FUNC, (GLint *)&amp;_currentAlphaTestFunc);
	    glGetFloatv(GL_ALPHA_TEST_REF, &amp;_currentAlphaTestRef);
	    glEnable(GL_ALPHA_TEST);
	    CHECK_GL_ERROR_DEBUG();
	    glAlphaFunc(GL_GREATER, _alphaThreshold);
	#endif
	}
}

//渲染结束，之后把模板状态还原，_currentStencilFunc值都是在执行visit之前从opengl里面获取的值。
void StencilStateManager::onAfterVisit()
{
    glStencilFunc(_currentStencilFunc, _currentStencilRef, _currentStencilValueMask);
    glStencilOp(_currentStencilFail, _currentStencilPassDepthFail, _currentStencilPassDepthPass);
    glStencilMask(_currentStencilWriteMask);
    if (!_currentStencilEnabled)
    {
        glDisable(GL_STENCIL_TEST);
    }
    s_layer--;
}
</code></pre>

<h3 id="section-1">关键函数：</h3>

<ol>
  <li><code>glStencilFunc</code>:用来规定是否通过了 <code>stencil test</code> 的规则。<br />
<code>glStencilFunc</code>的原形是: <code>glStencilFunc( GLenum func, GLint ref, GLuint mask)</code>;<br />
函数意义：指定模板测试比较函数，<strong>模板值</strong>与要写入的<strong>像素值</strong>做与操作，然后得到的结果，用第一个参数指定的函数和第二参数进行比较。如果满足则通过了模板测试。可以写入。否则不满足。</li>
  <li><code>glStencilOp</code>:向<code>stencil buffer</code> 中写内容的规则。<br />
<code>glStencilOp</code>(GLenum fail , GLenum zfail, GLenum zPss );<br />
函数意义：当某些图元在绘制的时候,如果模板测试失败(或者深度测试失败),它怎么修改其打算写入的位置的模板值</li>
</ol>

<p>如果是不调用了<code>setInverted</code>的话。就如下图所示。<br />
(图1)<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-1.png" alt="1" />(图2)<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-0.png" alt="0" /></p>

<p>调用<code>setInverted(true)</code>则如下图所示：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-a.png" alt="a" /><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-15-b.png" alt="b" /></p>

<p>鉴于此，我们知道将要draw上去的不会通过模板测试，但是却会将模板留下他的形状（凡是为1的地方才会被绘制）。接下来在绘制其他形状的东西时候。在模板测试这里，直接就会按照模板的样子draw出来。<br />
因此遮罩效果就有了！</p>

<h2 id="section-2">参考文档</h2>

<ol>
  <li><a href="http://www.jianshu.com/p/bed926e53517">OpenGL模板缓存</a></li>
  <li><a href="http://www.lxway.com/929242951.htm">对模板缓存的一些个人理解</a></li>
  <li><a href="http://blog.csdn.net/zenny_chen/article/details/5903925">深入了解OpenGL——帧缓存</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenGL基础之矩阵和坐标]]></title>
    <link href="http://www.newtomato.me/blog/2017/12/09/openglji-chu-ju-zhen-zhi-shi"/>
    <updated>2017-12-09T20:07:39+08:00</updated>
    <id>http://www.newtomato.me/blog/2017/12/09/openglji-chu-ju-zhen-zhi-shi</id>
    <content type="html"><![CDATA[<p>[TOC]</p>

<p>作为游戏开发者，我们将任何显示对象放到舞台上的时候，可能都没有想到在这后面有一套复杂又快速的东西保证了我们能够立马看到想要的效果。而这里背后的东西，我们称之为渲染引擎。</p>

<p><code>cocos2dx</code>使用便是<code>opengl</code>的图形编程接口。我们想要彻底搞懂cocos2dx，就需要了解opengl。而这里会介绍<code>opengl</code>矩阵和坐标的基础知识，最后搞明白上面提到的问题，一张图片是怎么渲染到舞台上的。</p>

<!--more-->

<h2 id="section">齐次坐标</h2>

<p>cocos2dx和opengl中，有大量的数学计算。例如比如位置的变化。通过代码我们知道，这些计算使用都是矩阵。<br />
这些矩阵有什么特别的？他们特别的在于都是4维矩阵。<br />
而cocos2dx最多是3维，opengl也是为3维设计的接口，为什么会有4维？</p>

<p>因为这样的坐标更容易进行矩阵乘法，他们被称之为齐次坐标。</p>

<blockquote>
  <p>在数学里，齐次坐标（homogeneous coordinates），或投影坐标（projective coordinates）是指一个用于投影几何里的坐标系统，如同用于欧氏几何里的笛卡儿坐标一般。该词由奥古斯特·费迪南德·莫比乌斯于1827年在其著作《Der barycentrische Calcul》一书内引入[1][2]。齐次坐标可让包括无穷远点的点坐标以有限坐标表示。使用齐次坐标的公式通常会比用笛卡儿坐标表示更为简单，且更为对称。齐次坐标有着广泛的应用，包括电脑图形及3D电脑视觉。使用齐次坐标可让电脑进行仿射变换，并通常，其投影变换能简单地使用矩阵来表示。<br />
如一个点的齐次坐标乘上一个非零标量，则所得之坐标会表示同一个点。因为齐次坐标也用来表示无穷远点，为此一扩展而需用来标示坐标之数值比投影空间之维度多一。例如，在齐次坐标里，需要两个值来表示在投影线上的一点，需要三个值来表示投影平面上的一点。</p>
</blockquote>

<p>上述介绍来源自维基百科对<strong>齐次坐标</strong>的介绍.<br />
注意，齐次坐标可以比笛卡尔坐标更为简单，且更为对称。事实上也的确如此。</p>

<h3 id="section-1">齐次坐标的特征</h3>

<p>我们举例说明什么是齐次坐标。一个二维坐标（x,y）,如果转为齐次坐标就是（kx,ky,k）。<br />
<code>规律就是他比原来坐标多一维。且有相同的系数。</code><br />
在这个规律下，(3,4)对应的齐次坐标可以是（3，4，1），（6，8，2），（9，12，3）等等。</p>

<h3 id="section-2">齐次坐标如何区分点和向量</h3>

<p>我们向量的表示和点的是一样的。（3，4）可以认为是一个点，也可以认为是从原点出发的一个指向(3,4)的向量。<br />
那么在齐次坐标中，是如何区分这两种不同的表示呢？<br />
向量的意义最重要的不是他的数值而是他的方向。而点没有方向，只有位置。所以上面提到的<code>k=0</code>，则表示此是向量坐标，而<code>k=1</code>表示这是一个点坐标.<br />
[3，4，0]是一个方向向量，而[3,4,1]则是一个位置。</p>

<h2 id="section-3">仿射变换</h2>
<p>向量或者点经过矩阵线性变化加平移之后，转换为另一个向量或者点。<br />
放射变化可以表示成为如下的公式：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115125390754949.jpg" alt="-w300" /></p>

<p>这个公式是通过矩阵的缩放旋转以及平移之后计算得到的。所以仿射变换是复合变换。是基本矩阵变换相乘得来的。<br />
因此我们先得知道基本的矩阵变换。</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-15128224606470.jpg" alt="" /></p>

<p>有了上述公式，我们可以基本写仿射变化的公式了。</p>

<p><code>P' = M(平移)*M(旋转) * M(缩放) * P</code></p>

<p><code>P</code>代表原先的坐标，经过缩放，旋转，平移之后转换成了新坐标<code>P'</code>。这里需要注意的一点是矩阵的乘法规则是从右到左，也就是对P坐标先做缩放，在做旋转，最后做平移。</p>

<p>根据矩阵的特性，我们可以知道矩阵平移其实可以做成矩阵相加。</p>

<pre><code>M0 = M1 + M2(M均是3维矩阵)
</code></pre>
<p>而其缩放和旋转都是矩阵相乘，做成4位齐次坐标最大的好处是将相加的矩阵也可以以相乘的方式来计算。统一的操作方法会带来很多便利。</p>

<p>上面的矩阵转换能够让我们在不同坐标系的点进行转换。举例说明，你在办公室的位置是相对办公室这个房间而言的。房间的原点假设在前台。此时你距离前台位置是（100，200，0）。0代表层级，都是同一层办公室，自然为0。此时如果要计算你在地球上的位置，怎么计算？<br />
自然已经知道地球原点在哪里，按照这个原点计算你的位置。</p>

<p>最简单的方法自然是直接计算，地球原点到你之间的物理距离。<br />
如此自然可以，可是不是最好的，也不是最快的。如果又求你在这个国家的位置，国家的原点在首都。再求你在这一条街的位置，再求你在这个地区的位置，这么多的需求，是不是觉得这个方法不是特别有效？</p>

<p>最有效的方法，就是使用仿射矩阵。</p>

<p>知道自己在办公室的位置，那么直接求办公室前台（办公室原点）对一楼门卫（大楼原点）之间的矩阵转换M1。套用公式就能知道自己在大楼里面的位置。然后在一条街的位置，那就求一楼门卫在这条街原点的矩阵转换M2。剩下的大家举一反三就知道了。</p>

<pre><code>P' = M(n)*M(n-1)*M(n-2)*...*M1*P
</code></pre>

<p>因此可以推论得知，空间坐标转换最重要的就是求解一个仿射矩阵。</p>

<p>在opengl的世界中，我们将要接触到很多空间转换的事情。</p>

<pre><code>本地屏幕坐标-&gt;世界坐标-&gt;观察坐标(摄像机坐标，eye坐标)-&gt;裁剪坐标-&gt;投影坐标-&gt;标准设备坐标-&gt;屏幕坐标

</code></pre>
<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115128146409840.png" alt="-w350" /><br />
因此在opengl中他的最终的参见坐标公式如下：</p>

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>V</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>c</mi>
      <mi>l</mi>
      <mi>i</mi>
      <mi>p</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <msub>
    <mi>M</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>p</mi>
      <mi>r</mi>
      <mi>o</mi>
      <mi>j</mi>
      <mi>e</mi>
      <mi>c</mi>
      <mi>t</mi>
      <mi>i</mi>
      <mi>o</mi>
      <mi>n</mi>
    </mrow>
  </msub>
  <mo>&#x22C5;<!-- ⋅ --></mo>
  <msub>
    <mi>M</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>v</mi>
      <mi>i</mi>
      <mi>e</mi>
      <mi>w</mi>
    </mrow>
  </msub>
  <mo>&#x22C5;<!-- ⋅ --></mo>
  <msub>
    <mi>M</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>m</mi>
      <mi>o</mi>
      <mi>d</mi>
      <mi>e</mi>
      <mi>l</mi>
    </mrow>
  </msub>
  <mo>&#x22C5;<!-- ⋅ --></mo>
  <msub>
    <mi>V</mi>
    <mrow class="MJX-TeXAtom-ORD">
      <mi>l</mi>
      <mi>o</mi>
      <mi>c</mi>
      <mi>a</mi>
      <mi>l</mi>
    </mrow>
  </msub>
</math>

<h2 id="section-4">坐标</h2>

<p>坐标是相对了坐标系而言的，坐标系最重要就是定义了原点。<br />
对于游戏中的模型或者显示对象，他们都有自己的坐标系。比如我们物体A里面有一个子节点B在位置（100，100）处，那么这里的（100，100）就是相对于A的<strong>本地坐标</strong>计算的来。使用本地坐标是最直观的。<br />
在这个游戏世界中，还有一个<strong>世界坐标系，或者是View坐标系。也可以理解成舞台坐标系</strong>。舞台的物体很多，他们每一个都有相对于舞台原点的坐标。甚至嵌套的子节点也会拥有一个唯一的舞台坐标。计算方法，对应思考上面的仿射矩阵变换。<br />
假设舞台很大，玩家会通过拖拽的方式移动屏幕看到其他部分。<br />
舞台移动之后会影响opengl显示的图像。按照上面的公式，其实变化的只有<code>M(view)</code>。后面和前面的矩阵都没有变化，因此计算位置就会很快。<br />
而这里计算<code>M(view)</code>矩阵，通过摄像机来计算会更快。因为移动物体其实就是反向移动摄像机。</p>

<p>裁剪空间是对世界空间的的范围裁剪。只有在规定范围内的才会被显示出来。这种就是投影。有正交投影和透视投影。<br />
正交投影产生的效果就是前后一致的裁剪。主要用于2D游戏。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115128184208022.png" alt="-w250" />(正交投影)</p>

<p>透视投影会出现近大远小的效果。主要在3D游戏中使用。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115128184007944.png" alt="-w250" />(透视投影)</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115128185556038.png" alt="-w250" />(图1)<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-12-09-115128157278548.jpg" alt="-w150" />(右手坐标系)</p>

<p>投影裁剪之后，只保留在视椎体内的坐标，然后将坐标转换为opengl要求的[-1，1]标准化设备坐标。<br />
最后<code>opengl</code>通过<code>glViewPort()</code>设定的屏幕分辨率将坐标有转换为屏幕坐标。</p>

<p>在这里使用opengl右手坐标系，因此上面(图1)中所示的坐标系就是opengl的坐标。在视椎体的正中心。因此x的坐标都会标准化成[-1,1]的范围。而y也同样如此。至于z，适用于深度测试来使用的，同一个z轴上的点，具体就是离near面近的点就可能直接使用，而其他的点可能被直接抛弃掉。</p>

<h2 id="section-5">接下来，扩展点什么</h2>

<p>这些矩阵变换和opengl坐标系的基础知识，能够更好的帮助我们理解接下来的矩阵推导。<br />
我们将要涉及的View矩阵(观察矩阵)和投影矩阵推导。<br />
而理解这两种矩阵推导又能帮助我们理解游戏引擎是如何将顶点数据传递给opengl，opengl又是如何处理这些顶点数据，展示到屏幕上来。</p>

<p>最后通过这些，我们会将cocos2dx的opengl渲染流程疏通一遍。更好去理解cocos2dx是如何运作的。</p>

<h2 id="section-6">参考链接</h2>

<ol>
  <li><a href="http://www.songho.ca/opengl/gl_projectionmatrix.html">OpenGL Projection Matrix</a></li>
  <li><a href="https://learnopengl-cn.readthedocs.io/zh/latest/01%20Getting%20started/08%20Coordinate%20Systems/">learnopengl-cn</a></li>
  <li><a href="https://oncemore2020.github.io/blog/homogeneous/">齐次坐标系入门级思考</a></li>
</ol>

]]></content>
  </entry>
  
</feed>
