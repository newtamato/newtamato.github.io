<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类:godot | 番茄手册]]></title>
  <link href="http://www.newtomato.me/blog/categories/godot/atom.xml" rel="self"/>
  <link href="http://www.newtomato.me/"/>
  <updated>2018-07-01T19:25:02+08:00</updated>
  <id>http://www.newtomato.me/</id>
  <author>
    <name><![CDATA[newtomato]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Godot引擎分析-1]]></title>
    <link href="http://www.newtomato.me/blog/2018/05/26/godot-1"/>
    <updated>2018-05-26T13:06:57+08:00</updated>
    <id>http://www.newtomato.me/blog/2018/05/26/godot-1</id>
    <content type="html"><![CDATA[<p>利用业余时间看了一个星期的godot源码，云里雾里的看不清全貌。记录一下这周的成果，为以后先打个基础。</p>

<p>此处声明，由于个人并没全部看明白，所以我只是分享一部分我看到的东西。我的分享未必都是全部正确的。如果有错误也非常欢迎指正出来。正所谓互相交流才能有所进步。</p>

<p>ok，闲话少说进入正题。<br />
<!--more--></p>

<h2 id="section">宏观角度看</h2>

<p>先从整体宏观的角度看一下GoDot引擎。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-26-15272453730540.jpg" alt="" /></p>

<p>从上面这张图上看，我们可以看出一下几点：</p>

<ul>
  <li>最上层<code>MainLoop</code>就是我们的游戏循环逻辑。所有游戏几乎都会有自己的main入口，然后在main函数中做到循环刷新屏幕。Godot也不例外。</li>
  <li>所有对象都继承自Object，Reference也是继承Object，只有Resource资源继承自Reference。Node，Canvas等显示对象却并不继承Reference。这和其他引擎不太一样。例如在cocos中所有对象都继承自Reference，几乎可以通过调用RefCount来检查对象的被引用的个数。</li>
  <li>Node有两大子类型，一个是<code>Canvas</code>，一个是<code>Spatial</code>。主要区别在于，<code>Canvas</code>是2d对象的父类，对应的<code>Spatial</code>是所有3D的父类。Canvas下又分成了<code>Control</code>和<code>Node2d</code>，<code>Control</code>是所有UI的父类，<code>Node2d</code>是所有2d物体的父类。例如我们实例化一个button，Lable，PopUpDialog，他们都是继承自Control。而我们实例化的<code>Sprite</code>，<code>Area2d</code>，都是继承自Node2d。为什么godot会将UI和Node2d区别对待呢？是因为底层对UI层做了优化，可以提升引擎的性能。怎么做到的呢？那就涉及到第四点。</li>
  <li>第二层是开发同学会经常用到的。创建一个物体，给他配上Texture或者Shader，Material。旋转移动物体，去碰撞另外一个物体等等。而这些效果背后真正实现他们，就是第三层。这一层包括物理引擎和渲染引擎还有声音。物理引擎就是负责告诉我们碰撞以及类似Camera需要渲染多少个物体。所以最关键的地方在于高效的碰撞检测算法。渲染引擎负责将Texture，Material，Shader等融合在一起，计算物体的Transform矩阵，准备顶点数据光照数据环境数据然后调用OpenGL命令上传GPU。</li>
</ul>

<p>上面的那张图大概介绍完了。很多同学估计对第三层很感兴趣，但是现在不是合适的时候。我们需要一步一步的来。</p>

<h3 id="section-1">从代码结构来看</h3>

<p>现在来说一下他的代码结构。了解代码结构有助于辅助我们看懂他的代码。从github上将他的代码clone下来之后，代码结构如下：</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-26-15273033285621.jpg" alt="" /><br />
这些大部分目录我们不用都去看，</p>

<pre><code>core：是对数据结构的定义。
platform：是各个平台一些不同处理。
doc：我们使用godot编辑器的时候，一些代码提示和文档。
scene：是第二层的实现。
main：就是第一层的实现。main入口类。以及mainloop等。这里会做初始化的一些操作。
modules：是一些模块的处理，字体，图片格式解析等。
servers：是第三层的实现。
thirdparty：暂时还没有没有看到。
editor：就是godot编辑器的实现。
</code></pre>

<p>看了上面的解释，是不是知道重点在哪里了。对！就是<strong>scene和servers</strong>。</p>

<p>scene主要是第二层的实现。包括2d，3d，gui，resource（例如texture，mesh，material，collision shape）。<br />
servers就是第三层的实现。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-26-15273037073232.jpg" alt="" /><br />
audio就不用说了，visual是负责渲染，physics_2d是2d的物理引擎。physics是3d的物理引擎。arvr就是时下较为流行的ARVR技术了。</p>

<p>所以如果你对任何一块儿感兴趣可以直接去看代码。看他是怎么实现的。不过相信我，硬啃代码绝对是事倍功半的买卖。</p>

<h2 id="section-2">通过一个例子来将整个引擎串起来</h2>

<p>从宏观的角度讲这么多，我们现在通过一个例子，将引擎怎么工作的给串起来。然后在从微观角度，更细节的去分析他的实现。</p>

<p>这个例子是：</p>

<p><strong>将一个Sprite放到舞台上，并给他一张图片，他是怎么被绘制屏幕上的？</strong></p>

<p>这个题目经常是一个前端工程师的面试题目。不同面试官有不一样的点。我这里并不给出答案，只是将流程说一下，所有点都在这里了。你们自行体会。</p>

<h2 id="section-3">应用业务层</h2>

<p>代码实现</p>

<pre><code>var sprite = Sprite.new()
var texture = ImageTexture.new()
texture.load("res://MainForm/bg_activityout.png")
sprite.centered = false
sprite.set_texture(texture)	
self.add_child(sprite)
</code></pre>

<p>ImageTexture加载图片的函数：</p>

<pre><code>void ImageTexture::load(const String &amp;p_path) {

	Ref&lt;Image&gt; img;
	img.instance();
	img-&gt;load(p_path);
	create_from_image(img);
}
</code></pre>

<p>Image位于core文件夹，是对图片信息的解析实现。不同格式的图片有各自的存储格式，比如说每个像素是按多少字节存储。而我们知道的是p_path即可。<br />
然后看看<code>create_from_image</code>函数。</p>

<pre><code>void ImageTexture::create_from_image(const Ref&lt;Image&gt; &amp;p_image, uint32_t p_flags) {

	ERR_FAIL_COND(p_image.is_null());
	flags = p_flags;
	w = p_image-&gt;get_width();
	h = p_image-&gt;get_height();
	format = p_image-&gt;get_format();

	VisualServer::get_singleton()-&gt;texture_allocate(texture, p_image-&gt;get_width(), p_image-&gt;get_height(), p_image-&gt;get_format(), p_flags);
	VisualServer::get_singleton()-&gt;texture_set_data(texture, p_image);
	_change_notify();
}
</code></pre>

<p>这个函数出现的如下两句就比较关键了：</p>

<p>VisualServer::get_singleton()-&gt;texture_allocate(texture, p_image-&gt;get_width(), p_image-&gt;get_height(), p_image-&gt;get_format(), p_flags);<br />
		VisualServer::get_singleton()-&gt;texture_set_data(texture, p_image);</p>

<p>这两个函数的实现就是开始调用opengl创建glBindTexture，glTexImage2D，然后将<code>tex_id</code>这个opengl句柄，赋值给我们刚刚创建的texutre。</p>

<p>VisualServer在platform那里初始化<strong>VisualServerRaster</strong>。但是它并没有texture_allocate函数，这个函数的真正实现是在<code>RasterizerStorageGLES3</code>或者<code>RasterizerStorageGLES2</code>，为什么会这么调用呢？这里算是给大家的一点思考。</p>

<h3 id="opengl">渲染层，设置opengl状态</h3>

<p>ok，我们直接来看一下第一个函数吧。</p>

<p>void RasterizerStorageGLES3::texture_allocate(RID p_texture, int p_width, int p_height, Image::Format p_format, uint32_t p_flags) {</p>

<pre><code>GLenum format;
GLenum internal_format;
GLenum type;

bool compressed;
bool srgb;

if (p_flags &amp; VS::TEXTURE_FLAG_USED_FOR_STREAMING) {
	p_flags &amp;= ~VS::TEXTURE_FLAG_MIPMAPS; // no mipies for video
}

Texture *texture = texture_owner.get(p_texture);
ERR_FAIL_COND(!texture);
texture-&gt;width = p_width;
texture-&gt;height = p_height;
texture-&gt;format = p_format;
texture-&gt;flags = p_flags;
texture-&gt;stored_cube_sides = 0;
texture-&gt;target = (p_flags &amp; VS::TEXTURE_FLAG_CUBEMAP) ? GL_TEXTURE_CUBE_MAP : GL_TEXTURE_2D;

_get_gl_image_and_format(Ref&lt;Image&gt;(), texture-&gt;format, texture-&gt;flags, format, internal_format, type, compressed, srgb);

texture-&gt;alloc_width = texture-&gt;width;
texture-&gt;alloc_height = texture-&gt;height;

texture-&gt;gl_format_cache = format;
texture-&gt;gl_type_cache = type;
texture-&gt;gl_internal_format_cache = internal_format;
texture-&gt;compressed = compressed;
texture-&gt;srgb = srgb;
texture-&gt;data_size = 0;
texture-&gt;mipmaps = 1;

glActiveTexture(GL_TEXTURE0);
glBindTexture(texture-&gt;target, texture-&gt;tex_id);

if (p_flags &amp; VS::TEXTURE_FLAG_USED_FOR_STREAMING) {
	//prealloc if video
	glTexImage2D(texture-&gt;target, 0, internal_format, p_width, p_height, 0, format, type, NULL);
}

texture-&gt;active = true; }
</code></pre>

<p>这个函数先是将Image读出来的p_width,p_height,p_format 等数据都赋值给texture，同时格局p_format来求出opengl需要的internal formate和formate，这两个参数在下面glTexImage2D是用得到的。我们例子中texture的target是GL_TEXTURE_2D。因此这里不会调用glTexImage2D。</p>

<p>opengl加载一个Texture需要有以下几个步骤。<br />
激活一个Texture，绑定到一个opengl变量上，设置他的状态，绑定图片数据。<br />
刚才那个函数并没有完成后续的步骤，所以我们还需要继续向下看，那就是看<code>texture_set_data</code>函数。<br />
这个函数代码太长，这里就不贴出来了。但是从这个代码中我们确实看到了他开始设置状态，绑定图片数据了。</p>

<p>至此，opengl状态已经设定完成。但还没有完，图像真正显示出来，是需要drawcall的。在何处，在何时进行的呢？</p>

<h3 id="gldraw">渲染层，开始glDraw*绘制</h3>

<p>这里的绘制是一个复杂的过程，我尽量以流程图的形势画出来。希望让大家有一个清晰的印象。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-26-15273102726934.jpg" alt="" /></p>

<p>所有的渲染命令会被添加到canvas对象的command队列中，而我们循环刷新逻辑在每帧去调用render_canvas，VisualServersCanvas有所有canvas对象，于是遍历循环开始。只要有canvas对象上有command队列就开始调用_canvas_item_render_command函数去<code>glDraw*</code></p>

<p>流程图不复杂，点到为止，你们按照上面的函数名挨个看下去，就能更清晰明了了。</p>

<h2 id="section-4">结束前的话</h2>

<p>相信看过代码的同学一定有很多困惑，里面那么多的状态设置，那么多if的分支都是干什么用的。感觉我说的很简单，但是代码讲了好多事情。不那么简单啊！<br />
是的，你说对了，因为我的业务简单，只绘制了一个Sprite，但是如果考虑到shader，考虑到混合，考虑到透明，考虑到光线等等，在回头去看绘制函数，是不是就有点明白了。<br />
因此要想真正搞明白绘制函数，需要对opengl有一定的了解，什么是vbo，vao，ufo，fbo以及如何更新数据等等。</p>

<p>接下来，我会从比较细节的地方去看引擎，顺便对opengl的接口函数做一下梳理。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Godot基础知识之事件穿透]]></title>
    <link href="http://www.newtomato.me/blog/2018/05/20/godot-event-1"/>
    <updated>2018-05-20T20:03:02+08:00</updated>
    <id>http://www.newtomato.me/blog/2018/05/20/godot-event-1</id>
    <content type="html"><![CDATA[<h2 id="section">什么是事件穿透</h2>

<p>场景上有一个物体A，B，B被A挡住，也就是我们能看到B的一部分。此时我们点击A（只有A的部分，没有挡住B的那部分），A会收到点击事件的通知。但是此时如果我们点击A，B交汇处，会发生什么？这就需要我们具体想让什么先发生。<br />
A，B均可以收到点击事件。收到事件会有一个先后顺序。一般会以显示顺序排序，前面的A会先收到。A收到之后，决定事件是否继续向下传递。如果传递了，就发生穿透。</p>

<p>大部分情况下，我们看到UI下面遮挡场景。点击UI，只希望UI收到点击事件。而UI下面遮挡的场景并不希望收到事件。事件由引擎触发，而由我们来决定是否终止。</p>

<p><code>EventSystem.current.IsPointerOverGameObject(Input.GetTouch(0).fingerId)</code>(用在u3d中)函数检测是否是在UI层，在cocos中，我们使用<code>onTouchBegan()</code>的返回值来判定是否被他吞掉。而在godot中是怎么实现的呢？</p>

<!--more-->

<h2 id="section-1">进入正文</h2>

<p>先来看看godot怎么解释他的input事件。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-20-152681301816391.png" alt="" /><br />
User触发了点击事件之后，事件在SceneTree中一直被传递。执行格子_input函数。从图中可以看出，先要寻找_input,如果没有_input最后会寻找_unhandled_input函数。</p>

<p>看这种图也不是很直观。我们来做一个测试。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-20-15268241267894.jpg" alt="w350" /><br />
展示的样子是：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-20-15268237116454.jpg" alt="w350" /></p>

<p>连个button，同时button下面还有一个Area。<strong>TestClick和Hud和Area均带有_input函数</strong>，当我点击button1的时候，输出的打印日志如下：</p>

<pre><code>[Hud]_input
[Area2]_input
[Area]_input
[TestClick]_input
[Hud]_on_Button_pressed
</code></pre>

<p>事件流是<strong>Hud:_input-&gt;Area2:_input-&gt;Area:_input-&gt;TestClick:_input-&gt;Hud.btn1的点击回调</strong>。</p>

<p>也就是在input事件发生的时候，Node只要有input函数，都会被执行一遍。<strong>注意这里只有button被执行，挡在后面的其他对象（他们都带有真正触发事件的_input_event函数）并没有触发。所以这里已经可以算是方案了</strong></p>

<h3 id="section-2">问题</h3>

<p><strong>如果想要在hud的input先发生，其他的input函数在后面执行，怎么办？</strong></p>

<p>API文档中提供了一个函数：<code>accept_event</code>。我们放到hud的input函数内。</p>

<pre><code>func _input(event):
	if event.is_pressed():
		print("[Hud]_input")
		accept_event()
</code></pre>

<p>结果打印就是：</p>

<pre><code>[Hud]_input
</code></pre>

<p>Button函数没有执行啊！这明显不是我们想要的。</p>

<p>幸运的是，我们还有一个<code>_unhandled_input</code>函数。此时我们将Area和TestClick的input函数全部换成这个函数。然后再次点击btn1，看看输出结果。</p>

<pre><code>[Hud]_input
[Hud]_on_Button_pressed
</code></pre>

<p>哈！达到了我们的基本目的，只有hud收到了事件。那么如果此时点击非Hud的地方会怎么样？比如我们直接点击非HUD，非Area（蓝色块）的那个黑色地方，看看输出吧。</p>

<pre><code>[Hud]_input
[Area2]_unhandled_input
[Area]_unhandled_input
[TestClick]_unhandled_input
</code></pre>

<p>这样看来事件流便是 <strong>Hud:_input-&gt;Area2:_unhandled_input-&gt;Area:_unhandled_input-&gt;TestClick:_unhandled_input</strong>。</p>

<p>此时在点击蓝色块的Area，他有一个_input_event()的函数，打印如下：</p>

<pre><code>[Hud]_input
[Area2]_unhandled_input
[Area]_unhandled_input
[TestClick]_unhandled_input
[Area]_on_Area_input_event
</code></pre>

<p>上述打印一定要认真看他们的顺序。</p>

<h2 id="section-3">结论</h2>

<p>那么我们直接先来看看结论:</p>

<p><strong>如果点击是发生在hud（control）上，他会触发所有的input函数。无论是control还是Area上的。如果不是发生在hud上的点击，则按照input先触发，在触发_unhandled_input的顺序去触发。</strong></p>

<p>所以再来看我们原先的问题：</p>

<p><strong>如何让hud的input优先级高于其他Node呢？</strong></p>

<p>相信读到这里的读者已经有些答案了，那就是让hud拥有input函数，其他Node只有_unhandled_input。亦或者真正的事件发生不要写在input中，而是在input_event中。input_event是按照显示顺序，在前面的对象如果有这个函数，后面的对象则不触发了。</p>

<p>好了，分享到此结束了。大家有更好的方法欢迎和我交流。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Godot基础知识之Transform坐标转换]]></title>
    <link href="http://www.newtomato.me/blog/2018/05/19/godot-transform-1"/>
    <updated>2018-05-19T21:45:56+08:00</updated>
    <id>http://www.newtomato.me/blog/2018/05/19/godot-transform-1</id>
    <content type="html"><![CDATA[<h2 id="section">为什么要介绍坐标矩阵 ？</h2>

<p>Godot是一个开源的游戏引擎，支持2D和3D，如果你好奇Unity里面的那些炫酷特效是怎么实现的，又苦于没有unity3d的源码，那么可以考虑阅读Godot源码来帮助你梳理3D的知识库。</p>

<p>从渲染的角度上看，3D和2D在差别不大，都是需要将Texture和顶点（Mesh）数据，位置信息，颜色，法线等数据提交到GPU那边。渲染采用语言有所不同，有的采用opengl也有用d3d。<br />
现在渲染管线支持可编程，可以通过编写顶点片段着色器去修改图像最终的显示效果。</p>

<p>但是从计算的角度而言，3D还比2D多一个轴，因为这个轴，涉及了很多坐标变化，矩阵转换可以说是3D开发过程中当之无愧的基础。点击事件最终会通过坐标转换，来决定是否点中某个带碰撞盒的物体，物理引擎模拟运动，也离不开矩阵转化。最普遍的碰撞事件，大量物体在场景中运动（暂且不考虑性能问题），最终检测两个物体是否碰撞，也是需要位置坐标等，比如基础的AABB盒碰撞。坐标矩阵的转换涉及到很多地方，例如投影矩阵的计算，常用的法线贴图是以切线空间为坐标系。存储也是3d坐标，最后还需要用模型的矩阵来获得法线转换矩阵。</p>

<p>所以说矩阵非常重要。<br />
而今天我们先来了解一下Godot中坐标是一个什么样子的？原点在何处？坐标如何转换。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-19-icon.png" alt="icon" /><br />
<!--more--><br />
## 进入正题</p>

<p>废话不多说了。开始吧。<br />
我们的目的是通过点击屏幕，得到他屏幕坐标，ViewPort坐标，以及里面Area坐标。</p>

<p>首先我们创建一个空的godot工程，并且创建一个空的场景，里面放置一个Node。命名TestClick。<br />
然后增加一个Area，并且为他添加一个Shape（用于碰撞），和Mesh用于展示他的样子的。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-19-15267174988040.jpg" alt="" /></p>

<p>此时一定要增加一个Camera，否则运行之后场景里面看不到任何东西。</p>

<p>然后在Area上绑定一个脚本。增加<code>_input(event)</code>和<code>_input_event(camera, event, click_position, click_normal, shape_idx)</code>两个函数。后一个需要connect一下。<br />
代码如下：</p>

<pre><code>func _input(event):
	if event.is_pressed():
		print("[_input]",event.get_instance_id())
		print("[_input]",event.position)	
func _on_Area_input_event(camera, event, click_position, click_normal, shape_idx):
	if event.is_pressed():
		print("[_input_event] ",event.get_instance_id())
		print("[_input_event]",click_position)
		print("[_input_event]",click_normal)
		print("[_input_event]",shape_idx)
		var newpos = global_transform.affine_inverse() * click_position
		print("[_input_event]",newpos)
		newpos.y = newpos.y * -1
		newpos += Vector3(1,1,0)
		newpos /= 2
		print("[_input_event]",newpos)
	pass # replace with function body
</code></pre>

<p>通过这些打印，可以得知，每次点击会触发这两个函数，但是传递的event并不是同一个对象。<br />
event.position是屏幕坐标，根据你的屏幕分辨率计算出来的屏幕坐标，是一个Vector2类型。<br />
而click_position则是一个Vector3类型的坐标，但是并不是Area的点击位置坐标，而是当前屏幕的点击坐标，是当前ViewPort的点击坐标。<br />
这里说一下ViewPort的原点和坐标系。ViewPort的坐标系类似如下图片。<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2018-05-19-15267189437356.jpg" alt="" /><br />
ViewPort是屏幕以屏幕的正中心为原点，x向右为正方向，y向上为正方向。正交投影下，ViewPort的区间是[-1，1]。但是Camera选择是透视投影，调整Camera的视角和far，near之后，区间就会发生变化。点击屏幕四个角，输出坐标。比较一下即可。<br />
但是我们需要的不是viewport坐标，而是Area的坐标，设置可以说是Area的屏幕坐标。</p>

<p>因此需要将viewport坐标转换成Area，使用的函数就是如下函数：</p>

<pre><code>var newpos = global_transform.affine_inverse() * click_position
</code></pre>

<p><code>global_transform</code>是Area的全局变换。我们求得他的逆转换。然后对<code>click_position</code>进行这个逆转换。就可以将viewport的坐标转成Area的本地坐标。这里注意的是：Area的坐标系和ViewPort一样，x,y的范围是[-1,1],也就是他的原点在Area的中心，为了转换成我们熟悉的原点坐标在左上角。还是需要对他进行特殊处理。</p>

<pre><code>newpos.y = newpos.y * -1
newpos += Vector3(1,1,0)
newpos /= 2
</code></pre>

<p>此时newpos的x，y就是以左上角为原点的。</p>

<p>另外一些提示，我们添加的是Node，那里有viewport呢？那么问题来了，TestClick是根节点么？<br />
在它的_ready()函数中，我们添加如下代码，看看根到底是个什么对象。</p>

<pre><code>print(get_node("root"))
</code></pre>

<p>打印出来是<strong>ViewPort</strong>,非常意外。原来我们增加的Node并不是根，而是根里面第一个子节点。</p>

<h2 id="section-1">扩展</h2>

<p>如果要将area里面的本地坐标转换成全局坐标怎么做呢？<br />
调用他的to_global()函数即可。全局坐标转换为本地坐标呢？to_local()!<br />
看看他的函数代码：</p>

<pre><code>Vector3 Spatial::to_local(Vector3 p_global) const {
	return get_global_transform().affine_inverse().xform(p_global);
}
Vector3 Spatial::to_global(Vector3 p_local) const {
	return get_global_transform().xform(p_local);
}
</code></pre>

<p>我们刚刚的工程里面刚好可以直接使用to_local()即可。不用非得自己用transform来转换了。<br />
而上面这些矩阵转换和unity除了用法不同，原理是一样的。ViewPort的坐标原点不同，Unity中ViewPort的原点在左下角，右上角是（1，1）。并且转换世界坐标到本地坐标，和本地到世界坐标的转换。使用的Transform.transformPoint()以及InverseTransformPoint()。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用GoDot引擎制作一款mini小游戏]]></title>
    <link href="http://www.newtomato.me/blog/2017/05/23/shi-yong-godot"/>
    <updated>2017-05-23T16:33:36+08:00</updated>
    <id>http://www.newtomato.me/blog/2017/05/23/shi-yong-godot</id>
    <content type="html"><![CDATA[<p>Godot是一款高级，多功能，跨平台的2D和3D开源游戏引擎。其基本功能和Unity类似。<br />
他采用GDScript脚本语言，语法类似Python。简单易学。开发IDE工具体积很小，支持功能复杂，包括UI编辑，动画编辑，光照，Shader，寻路导航。不同类型碰撞检测等。</p>

<p>今天我们就通过一个小游戏来熟悉一下这个引擎。小游戏的效果如下</p>

<p><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-hunter.gif" alt="hunte" /></p>

<p>这是个2D的游戏，玩家控制英雄四处移动旋转，控制开枪，消灭包围过来的敌人。<br />
<!--more--></p>

<p>需要考虑的问题有</p>

<ol>
  <li>制作UI，上面有是哪个lable。</li>
  <li>多点触摸，如何同时控制两个左右两个控制器。左边控制移动旋转，右侧控制开枪</li>
  <li>敌人的生成和目标追踪。</li>
  <li>数据更新。例如上面杀死的敌人数量是有变化的。</li>
</ol>

<h3 id="section">游戏结构介绍</h3>

<p>游戏的场景结构如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955237845110.jpg" alt="=w300" /></p>

<p>整个root下面有一个大的节点Node2D,TextureFrame被我用来做背景。Player就是我们将要控制的英雄。<br />
animal_layer是敌人层。所有敌人都被放到这里，便于管理和控制。Timer是用来计时，用于每隔1秒开始生成新的敌人逻辑。info和info2以及fps都是界面上UI的展示。console就是我们的控制器。<br />
在这张图上可以看到有三个节点绑定了脚本，一个是Node2D，用于管理和生成敌人。一个是Player，另外一个是console。</p>

<p>Player上多一个影片剪辑一样的图标，这表示他里面还有子元件，双击它打开，里面的样式如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955241457399.jpg" alt="=w300" /><br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955244267190.jpg" alt="=w100" /></p>

<p>AnimatedSprite是一个类似序列帧一样的动画，可以程序控制固定展示第几张图片。我这里有三张图片，一张是表示idel状态，一张是奔跑状态，还有一张是开枪状态。默认是第一张，开枪则会设置set_frame(2)这样展示第三种状态了。</p>

<p>firePosition是一个点，用来占位。开枪之后，子弹会从这个地方发射。</p>

<h3 id="section-1">英雄控制</h3>

<p>OK，下面我们来说一下，最有意思的地方，那就是如何控制移动和旋转英雄。<br />
移动的函数是<code>set_pos()</code>,<code>translate()</code>。旋转的函数是<code>set_rot(),set_rotd()</code>,一个是控制弧度，一个是控制角度。</p>

<p>我采用的是set_pos()，和set_rot(),</p>

<pre><code>angle = 玩家触摸的目标点和当前位置之间的夹角
directionVector = 当前位置到玩家触摸点的方向向量
get_node("Player").set_pos(directionVector * SPEED * delta)
get_node("Player").set_rot(angle)
</code></pre>

<p>上述代码需要求得angle和directionVector，有了这两个变量，Player就可以受我们的控制了。而这两个变量刚好是<code>console</code>这个节点负责提供的。<br />
console的样式如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955248782400.jpg" alt="=w300" /><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955248919593.jpg" alt="=w300" /></p>

<p>玩家触摸左边的控制器，（确切说是整个控制器一分为2，触摸整个左侧任何位置），根据触摸的点，和圆中心的点，可以计算得到angle和directionVector。<br />
触摸右边的控制器，控制开火。</p>

<pre><code>func _input(event):
	if event.type == InputEvent.MOUSE_BUTTON:
		if event.is_pressed():
			pass
		else:
			get_node("touch").set_pos(Vector2(0,0))
			get_parent().get_node("Player").set_walking(false);
	if event.type == InputEvent.MOUSE_MOTION :
		if Input.is_mouse_button_pressed(BUTTON_LEFT) :
			if event.pos.x &gt; get_viewport_rect().size.width/2:
				return
			get_parent().get_node("Player").set_walking(true);
			var localPos = get_local_mouse_pos() 
			var maxRadius = self.get_texture().get_width()/2;
			var minRadius = self.get_node("touch").get_texture().get_width()/2;
			var offset = maxRadius - minRadius
			var startPos = Vector2(0,0)
			var distance = localPos.distance_to(startPos)
			var direction = (localPos - startPos).normalized()
			if distance &gt;= offset:
				localPos = direction * offset;
	
			get_node("touch").set_pos(localPos);
			
			var angle = localPos.angle_to_point(startPos);
			get_parent().get_node("Player").set_rot(angle)
			get_parent().get_node("Player").set_direction(direction);
			
	if event.type == InputEvent.SCREEN_TOUCH:
		#_point[event.index] = {pressed = event.pressed,pos = event.pos}
		var event2 = get_node("aim").make_input_local(event)
		if get_node("aim").get_item_and_children_rect().has_point(event2.pos):
			if event2.pressed == true:
				#get_node("aim").set_scale(Vector2(0.5,0.5))
				get_parent().get_node("Player").startToShoot()
			else:
				get_node("aim").set_scale(Vector2(1,1))

</code></pre>

<p>这里我用的是mouse_motion来计算玩家的对左侧控制器的控制。由于是多点触摸InputEvent.SCREEN_TOUCH会派发多次，程序可以通过event.index来追踪用的是那个点被点击了。index=0，表示第一个点被点击，index=1，表示第二个点被点击，然后通过event.is_pressed()来检查是否是玩家松开了手指。</p>

<p>至于怎么打开多点触摸，在godot这里模拟器中还没有找到合适的方法，我的做法是编译好pck，运行到ios的模拟器上，这样测试。比较麻烦一些吧。</p>

<h3 id="section-2">敌人的生成</h3>

<p>为了简单，敌人的生成是没有做缓存池机制的。通过Timer,每隔一秒创建一个敌人，然后添加到animal_layer上面。将Player节点传递给敌人。敌人通过updater函数去追踪player的位置。</p>

<pre><code>	var enemy = preload("res://hunter/AnimalArea2D.tscn").instance()
	enemy.connect("enemy_dead_signal",self,"_on_enemy_dead_handler");
	enemy.set_target(get_node("Player"))
	_index += 1
	enemy.set_name("animal_%d" % _index)
	get_node("animal_layer").add_child(enemy)
	enemy.set_pos(pos)
</code></pre>
<p>敌人的追踪代码如下：</p>

<pre><code>func _process(delta):
	if _target != null and _target extends preload("res://hunter/Player.gd"):
		var pos = _target.get_global_pos()
		look_at(pos)
		if _isDead == true:
			return

		var distance = pos - get_global_pos()
		if distance.length() &lt; 80:
			return
		translate(distance.normalized() * delta * SPEED)
</code></pre>

<p>敌人的结构如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955257583598.jpg" alt="=w200" /><br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955257655740.jpg" alt="=w300" /></p>

<p>敌人里面多了几个UI组件。一个是进度条，用于控制血量的展示。一个是爆炸效果。被子弹击中之后，触发这个效果。name的Lable组件。还有一个就是碰撞区域，上面蓝色的圆形区域。用于检测子弹是否碰撞到敌人身上。<br />
子弹的结构如下：<br />
<img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955260774599.jpg" alt="" /><img src="http://7xuepc.com1.z0.glb.clouddn.com/2017-05-23-14955260863005.jpg" alt="=w300" /></p>

<p>因此当子弹进入到敌人的圆形区域后，会触发body_enter事件。我们可以通过这个事件判定是否被击中了。</p>

<p>上面创建敌人的时候，敌人connect了一个<strong>信号</strong>（事件），就是<code>enemy_dead_signal</code>，这个事件如果触发了会被<code>_on_enemy_dead_handler</code>接收到然后处理。</p>

<p>这个信号怎么派发的？和事件一样，那么怎么携带参数呢？</p>

<p>下面我们就开始说一下第四条，怎么处理数据更新。</p>

<h3 id="section-3">数据更新</h3>
<p><code>enemy_dead_signal</code>是一个信号，而不是一个简单的字符串。在GDScript语法中，定义一个信号的语法如下：</p>

<p><code>signal enemy_dead_signal</code></p>

<p>这样enemy_dead_signal就被做成了信号，但是也只有定义它的组件可以派发。</p>

<pre><code>emit_signal("enemy_dead_signal"）
</code></pre>
<p>这里派发信号，用的又是字符串enemy_dead_signal，因此在我看来，enemy_dead_signal是相当于信号的name，具有唯一性。信号名不能再同一个对象上重复。它应该是挂在对象这个空间里，根据信号名找到真正的信号。然后把信号发射出去。</p>

<p>如何携带参数呢？那就需要修改信号的定义了。修改如下</p>

<pre><code>signal enemy_dead_signal(val1,val2,...)
</code></pre>

<p>这样我们发射信号就将参数放在后面即可。</p>

<pre><code>emit_signal("enemy_dead_signal",参数1，参数2）
</code></pre>

<p>这样当我们收到敌人死亡的信号，将数据更新。然后 get_node(“info2”).set_text( 死亡敌人数 : num_dead)</p>

<h3 id="section-4">结语</h3>

<p>这个游戏大致的结构和核心的代码差不多已经讲完。可以看到godot将一切都看成是node，node绑定脚本。脚本负责逻辑。因此脚本可能会非常大。不方便维护，不像是unity组件化的思想，逻辑拆分成不同组件。方便维护。<br />
相对unity，godot显得有点小众。不过，对于开发一个独立游戏，除了rpgMaker，GMS之外，又多了一个这样的开源引擎，还是不错的。<br />
感兴趣的同学们，移步到官方<a href="https://godotengine.org/news">网站</a>去看看，他们一直在努力做新的东西。</p>

]]></content>
  </entry>
  
</feed>
